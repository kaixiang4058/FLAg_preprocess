{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a8dc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import argparse\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a8b378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('--pklroot_label', default=\"./dataset/pkl/MRCPS_p512_s384_label_level0/\")\n",
    "# parser.add_argument('--pklroot_unlabel', default=\"./dataset/pkl/MRCPS_p512_s512_unlabel_level0/\")\n",
    "# parser.add_argument('--saveroot', default=\"./dataset/\")\n",
    "# args = parser.parse_args()\n",
    "\n",
    "pklroot_label = \"./dataset/pkl/MRCPS_p512_s384_label_level0/\"\n",
    "pklroot_unlabel = \"./dataset/pkl/MRCPS_p512_s512_unlabel_level0/\"\n",
    "saveroot = \"./dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6794b491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file name to list\n",
    "label_list=[]\n",
    "tmp_list = os.listdir(pklroot_label)\n",
    "for tmp in tmp_list:\n",
    "    if tmp.split('.')[-1] == 'pkl':\n",
    "        label_list.append(tmp.split('.')[0])\n",
    "\n",
    "\n",
    "unlabel_list=[]\n",
    "tmp_list = os.listdir(pklroot_unlabel)\n",
    "for tmp in tmp_list:\n",
    "    if tmp.split('.')[-1] == 'pkl':\n",
    "        unlabel_list.append(tmp.split('.')[0])\n",
    "\n",
    "\n",
    "label_num = len(label_list)\n",
    "print(f'label total number: {label_num}')\n",
    "print(f'unlabel total number: {len(unlabel_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cb8635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label list divide to label set \n",
    "order=['train','valid','test']\n",
    "ratio=[7,1,2]   #label data ratio each stage\n",
    "data_dict = {'train':{},'valid':{},'test':{}}\n",
    "\n",
    "if label_num<3:\n",
    "    for dk in data_dict.keys():\n",
    "        data_dict[dk]['label']=label_list\n",
    "else:\n",
    "    rand_index = list(range(label_num))\n",
    "    random.shuffle(rand_index)  #radnom\n",
    "    for i in range(len(order)):\n",
    "        data_dict[order[i]]['label'] = [label_list[rand_index[i]]]\n",
    "    \n",
    "    accumulate = 0\n",
    "    ratio_accumulate=[]\n",
    "    for v in ratio:\n",
    "        accumulate+=v\n",
    "        ratio_accumulate.append(accumulate)\n",
    "    for i in range(len(order)):\n",
    "        now_i = round(ratio_accumulate[i]/accumulate*(label_num-3))\n",
    "        new_list = []\n",
    "        if i == 0:\n",
    "            pre_i = 0\n",
    "        else:\n",
    "            pre_i = round(ratio_accumulate[i-1]/accumulate*(label_num-3))\n",
    "            \n",
    "        for index in rand_index[pre_i+len(order):now_i+len(order)]:\n",
    "            new_list.append(label_list[index])\n",
    "        \n",
    "        data_dict[order[i]]['label'] += new_list\n",
    "        print(f'label_{order[i]} number: {len(new_list)+1}')\n",
    "\n",
    "# unlabel list divide to unlabel set\n",
    "data_dict['train']['unlabel']=unlabel_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fcdd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save datalist\n",
    "save_path = os.path.join(saveroot, 'datalist.json')\n",
    "with open(save_path, 'w') as jw:\n",
    "    json.dump(data_dict, jw)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
