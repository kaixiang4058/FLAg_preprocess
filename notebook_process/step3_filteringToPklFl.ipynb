{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5edd337",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pyvips\n",
    "import numpy as np\n",
    "import pickle\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from itertools import repeat\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d3b99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_WSI(wsi_path, data_type, level):\n",
    "    slice = None\n",
    "    if data_type == 'tif':\n",
    "        slice = pyvips.Image.tiffload(wsi_path, page=level)\n",
    "    elif data_type in ['svs','ndpi','mrxs']:\n",
    "        slice = pyvips.Image.new_from_file(wsi_path, level=level)\n",
    "    else:\n",
    "        print('type not include')\n",
    "    return slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dc54ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filetering(data, img_region, roi_region, mask_region, img_slide_band, mask_slide_band, patch_size, processtype):\n",
    "    '''\n",
    "    judge patch class\n",
    "    process flow consider processtype:\n",
    "        label:   in_roi(if roi and mask), all(if mask) \n",
    "        unlabel: out_roi(if roi and mask), all(if no mask)\n",
    "    return: workflag, class, roi_check(err:true), mark_check(err:true)\n",
    "    '''\n",
    "\n",
    "    #check in roi range\n",
    "    mark_check = False\n",
    "\n",
    "    ##fetch roi, img, mask patch from tif and check work\n",
    "    if roi_region is not None:\n",
    "        patchroi = roi_region.fetch(data[1][0], data[1][1], patch_size, patch_size)\n",
    "        roiarea = np.ndarray(buffer=patchroi, dtype=np.uint8,\n",
    "                             shape=[patch_size, patch_size, mask_slide_band])\n",
    "        if np.average(roiarea) <1:  #out roi -> label skip\n",
    "            if processtype=='label':        #--------------------------------\n",
    "                return False, None, True, None\n",
    "        else:                       #in roi -> unlabel skip\n",
    "            if processtype=='unlabel':\n",
    "                return False, None, True, None\n",
    "    #=> no_roi, in_roi+label, not_entire_ori+unlabel\n",
    "    \n",
    "    mask = None\n",
    "    if processtype=='label':\n",
    "        if not (mask_region is None):\n",
    "            maskdata = mask_region.fetch(data[1][0], data[1][1], patch_size, patch_size)\n",
    "            mask = np.ndarray(buffer=maskdata, dtype=np.uint8, \n",
    "                            shape=[patch_size, patch_size, mask_slide_band])\n",
    "        else:\n",
    "            return False,None,None,None\n",
    "    elif processtype=='unlabel' and  not(mask_region is None):\n",
    "        return False,None,True,None\n",
    "\n",
    "    #=> no_roi+mask+label, no_roi+unlabel, in_roi label+mask+label, not_entire_ori+unlabel\n",
    "    patchdata = img_region.fetch(data[1][0], data[1][1], patch_size, patch_size)\n",
    "    img = np.ndarray(buffer=patchdata, dtype=np.uint8, \n",
    "                     shape=[patch_size, patch_size, img_slide_band])\n",
    "    if img.shape[2] == 4:\n",
    "        img = img[:, :, 0:3]\n",
    "    \n",
    "    ##class judgement\n",
    "    np.seterr(divide='ignore', invalid='ignore')\n",
    "\n",
    "    # check saturation -> rgb too close -> gray no color info(white/black no saturation)\n",
    "    sat = np.nan_to_num((np.amax(img, axis=2) - np.amin(img, axis=2))/255)\n",
    "    pix_sat_count = (sat > 0.2).sum() \n",
    "    all_pix_count = (sat > -1).sum()\n",
    "    count_max = all_pix_count * 0.6 #unlabel 0.75, label 0.9, highqulity 0.5\n",
    "    count_min = all_pix_count * 0.4 #unlabel 0.3, label, highqulity0.2\n",
    "\n",
    "    # check avgcolor -> each pixel too close avg -> background \n",
    "    img_avg = np.average(img, axis=2)\n",
    "    avg_divide = np.int32(img_avg)-np.int32(np.average(img_avg))\n",
    "    avg_divide[avg_divide<0]=-avg_divide[avg_divide<0]\n",
    "    avg_divide_count = (avg_divide<10).sum()\n",
    "    all_divide_count = (avg_divide > -1).sum()\n",
    "    same_color_check = True if avg_divide_count>0.95*all_divide_count else False\n",
    "\n",
    "    # color check (H&E stain focus on red color)\n",
    "    gr_div_count = (np.uint8((np.int32(img[:,:,1])-np.int32(img[:,:,0])).clip(min=0))>100).sum()\n",
    "    br_div_count = (np.uint8((np.int32(img[:,:,2])-np.int32(img[:,:,0])).clip(min=0))>50).sum()\n",
    "\n",
    "    if pix_sat_count <= (count_min):\n",
    "        target = 'white_background'\n",
    "    elif same_color_check:\n",
    "        target = 'white_background'\n",
    "    elif (gr_div_count>count_min or br_div_count>count_min):\n",
    "        target = 'white_background'\n",
    "        mark_check = True\n",
    "\n",
    "    elif pix_sat_count < count_max and pix_sat_count > count_min:\n",
    "        if mask is not None and 1 in mask:            \n",
    "            target = 'partial_tissue_wtarget'\n",
    "        else:\n",
    "            target = 'partial_tissue'\n",
    "    elif pix_sat_count >= count_max:\n",
    "        if mask is None or 1 not in mask:\n",
    "            target = 'tissue_background'   \n",
    "        elif 0 in mask:\n",
    "            target = 'partial_frontground' \n",
    "        else:\n",
    "            target = 'whole_frontground'\n",
    "\n",
    "    # if target=='tissue_background' and processtype=='unlabel':\n",
    "    #     cv2.imshow(target,img)\n",
    "    #     cv2.waitKey(0)\n",
    "   \n",
    "    return True, target, False, mark_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b8e409",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pruning(tifroot, maskroot, roiroot, save_path, name, datainfo, level, scale_level, processtype):\n",
    "    '''\n",
    "    read wsi file\n",
    "    use data location list check each patch class -> filtering()\n",
    "    save class dict info (contain patches' location)\n",
    "    '''\n",
    "\n",
    "    results = {\n",
    "        'white_background' : [],        # non tissue background\n",
    "        'tissue_background' : [],       # tissue but non labeled\n",
    "        'partial_tissue' : [],          # partial non labeled tissue and white backgorund \n",
    "        'whole_frontground' : [],       # almost labeled\n",
    "        'partial_frontground' : [],     # partial labeled and white backgorund \n",
    "        'partial_tissue_wtarget' : []   \n",
    "    }\n",
    "\n",
    "    ##read tif (wsi, roi, mask) \n",
    "    tifpath = os.path.join(tifroot, f'{name}'+'.'+datainfo['data_type'])\n",
    "    img_slide = read_WSI(tifpath, datainfo['data_type'], scale_level)\n",
    "    img_region = pyvips.Region.new(img_slide)\n",
    "\n",
    "    roi_region = None\n",
    "    if not (roiroot is None):\n",
    "        roipath = os.path.join(roiroot, f'{name}'+'.'+datainfo['data_type'])\n",
    "        if os.path.exists(roipath):\n",
    "            roi_slide = read_WSI(roipath, datainfo['data_type'], scale_level)\n",
    "            roi_region = pyvips.Region.new(roi_slide)\n",
    "\n",
    "\n",
    "    mask_region, mask_bands = None, None\n",
    "    if not (maskroot is None):\n",
    "        maskpath = os.path.join(maskroot, f'{name}'+'.'+datainfo['data_type'])\n",
    "        if os.path.exists(maskpath):\n",
    "            mask_slide = read_WSI(maskpath, datainfo['data_type'], scale_level)\n",
    "            mask_region = pyvips.Region.new(mask_slide)\n",
    "            mask_bands = mask_slide.bands\n",
    "\n",
    "    ##class assign\n",
    "    for data in datainfo['datas']:\n",
    "        workflag, target, roi_check, mark_check= filetering(\n",
    "                    data = data,\n",
    "                    img_region = img_region,\n",
    "                    roi_region = roi_region,\n",
    "                    mask_region = mask_region,\n",
    "                    img_slide_band = img_slide.bands,\n",
    "                    mask_slide_band = mask_bands,\n",
    "                    patch_size = datainfo['patch_size'],\n",
    "                    processtype = processtype\n",
    "                    )\n",
    "        data[1][0] = int(data[1][0]*datainfo['magnification'])\n",
    "        data[1][1] = int(data[1][1]*datainfo['magnification'])\n",
    "        if workflag:\n",
    "            results[target].append(data)\n",
    "        if mark_check:\n",
    "            markset.add(name)\n",
    "\n",
    "    ## save result\n",
    "    #skip non result\n",
    "    result_sum = 0\n",
    "    for r_v in results.values():\n",
    "        result_sum+=len(r_v)\n",
    "\n",
    "    if result_sum>0: \n",
    "        #pkl format\n",
    "        with open(os.path.join(save_path, f\"{name}.pkl\"), 'wb') as f:\n",
    "            pickle.dump(results, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        #transfer dict format to dataframe\n",
    "        rows = []\n",
    "        for key, values in results.items():\n",
    "            for value in values:\n",
    "                rows.append({\"key\": key, \"label\": value[0], \"coordinates\": value[1]})        \n",
    "        results_df = pd.DataFrame(rows)\n",
    "        feather_path = os.path.join(save_path, f\"{name}.feather\")\n",
    "        results_df.to_feather(feather_path)\n",
    "\n",
    "\n",
    "    stat_result = {\n",
    "            \"white_background\" : len(results['white_background']),\n",
    "            \"tissue_background\" : len(results['tissue_background']),\n",
    "            \"whole_frontground\" : len(results['whole_frontground']),\n",
    "            \"partial_frontground\" : len(results['partial_frontground']),\n",
    "            \"partial_tissue\" : len(results['partial_tissue']),\n",
    "            \"partial_tissue_wtarget\" : len(results['partial_tissue_wtarget']),\n",
    "        }\n",
    "\n",
    "    return name, stat_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977246fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPatchDict(tifroot, datalist, save_path, patch_size, stride_size, level, scale_level):\n",
    "    '''\n",
    "    create dict which use key as filename and record each patch locations(left+top) in file.\n",
    "    '''\n",
    "    #need finish skip from already saved file\n",
    "    check_dict = {'data':[],\n",
    "                 'error':[]}\n",
    "    datainfo_dict = {}\n",
    "\n",
    "    for dataname in tqdm(datalist):\n",
    "        data_type = dataname.split('.')[-1]\n",
    "\n",
    "        if data_type=='svs':\n",
    "            magnification = pow(4,(scale_level-level))\n",
    "        elif data_type in ['tif','tiff','ndpi','mrxs']:\n",
    "            magnification = pow(2,(scale_level-level))\n",
    "        else:\n",
    "            continue\n",
    "        patch_size_drop = int(patch_size/magnification)\n",
    "        stride_size_drop = int(stride_size/magnification)\n",
    "\n",
    "        name = dataname[:-(len(data_type)+1)]\n",
    "        \n",
    "        try:\n",
    "            slice = read_WSI(os.path.join(tifroot, dataname), data_type, scale_level)\n",
    "            if slice is None:\n",
    "                continue\n",
    "            check_dict['data'].append(os.path.join(tifroot, dataname))\n",
    "        except:\n",
    "            check_dict['error'].append(os.path.join(tifroot, dataname))\n",
    "            continue\n",
    "\n",
    "        width = slice.width\n",
    "        height = slice.height\n",
    "        datas = []\n",
    "        for sy in range(0, height-patch_size_drop-1, stride_size_drop):\n",
    "            for sx in range(0, width-patch_size_drop-1, stride_size_drop):\n",
    "                datas.append([name, [sx, sy], data_type])\n",
    "\n",
    "        datainfo_dict[name] = { 'data_type':data_type,\n",
    "                                'patch_size':patch_size_drop,\n",
    "                                'stride_size':stride_size_drop,\n",
    "                                'magnification':magnification,\n",
    "                                'width':width,\n",
    "                                'height':height,\n",
    "                                'datas':datas\n",
    "                            }\n",
    "\n",
    "    with open(os.path.join(save_path, \"check_list.json\"), 'w') as f:\n",
    "        json.dump(check_dict, f)\n",
    "\n",
    "    return datainfo_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6778b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute(tifroot, maskroot, roiroot, save_path, \\\n",
    "            datalist, patchsize = 256, stride_size = 256, level=0, scale_level=2, processtype='label', maxworkers=1):\n",
    "    #get patch dict (each patch locations in tif)\n",
    "    datainfo_dict = getPatchDict(tifroot, datalist, save_path, patchsize, stride_size, level, scale_level)\n",
    "    \n",
    "    total_stats = {}\n",
    "    \n",
    "    if maxworkers>1:\n",
    "        # multiple process\n",
    "        with ProcessPoolExecutor(max_workers=maxworkers) as exe:\n",
    "            pbar = tqdm(exe.map(pruning, repeat(tifroot), repeat(maskroot), repeat(roiroot), repeat(save_path),\n",
    "                        datainfo_dict.keys(), datainfo_dict.values(), repeat(level), repeat(scale_level), repeat(processtype)\n",
    "                        ))\n",
    "            for name, stat_result in pbar:\n",
    "                total_stats[name] = stat_result\n",
    "    else:\n",
    "        # single process\n",
    "        for pk in tqdm(datainfo_dict.keys()):\n",
    "            name, stat_result = pruning(tifroot, maskroot, roiroot, save_path, pk, datainfo_dict[pk], level, scale_level, processtype)\n",
    "            total_stats[name] = stat_result\n",
    "\n",
    "    with open(os.path.join(save_path, f\"result_statistic_{processtype}.json\"), 'w') as f:\n",
    "        json.dump(total_stats, f)\n",
    "\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8091b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('--tifroot', default=\"./dataset/images/\")\n",
    "# parser.add_argument('--maskroot', default=\"./dataset/masks/\")\n",
    "# parser.add_argument('--roiroot', default=\"./dataset/rois/\") \n",
    "# parser.add_argument('--saveroot', default=\"./dataset/pkl/\")\n",
    "# args = parser.parse_args()\n",
    "\n",
    "# tifroot = args.tifroot\n",
    "# maskroot = args.maskroot\n",
    "# roiroot = args.roiroot\n",
    "# saveroot = args.saveroot\n",
    "\n",
    "tifroot = './dataset/images/'\n",
    "maskroot = './dataset/masks/'\n",
    "roiroot = './dataset/rois/'\n",
    "saveroot = './dataset/pkl/'\n",
    "os.makedirs(saveroot, exist_ok=True)\n",
    "\n",
    "level = 0                                   # based page of tif (page trainset used )\n",
    "scale_level = 2                             # filter used page of tif (1 level drop twofold, but in svs 1 level drop fourfold)\n",
    "\n",
    "name='MRCPS'                                #folder name\n",
    "PATCHSIZE = 512\n",
    "STRIDESIZE = [384, 512]\n",
    "datatypes = ['label','unlabel']             #process type\n",
    "\n",
    "MAXWORKERS = 4\n",
    "markset = set()\n",
    "\n",
    "rct = time.time()\n",
    "for t_i in range(len(datatypes)):\n",
    "    save_dirname = f'{name}_p{PATCHSIZE}_s{STRIDESIZE[t_i]}_{datatypes[t_i]}_level{level}'\n",
    "    print(f\"Start {save_dirname}\")\n",
    "\n",
    "    #save path of each type (train, test, unlabel)\n",
    "    save_path = os.path.join(saveroot, save_dirname)\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "    #read tifs list\n",
    "    datalist = os.listdir(tifroot)\n",
    "\n",
    "    #run with multi-process process\n",
    "    execute(tifroot, maskroot, roiroot, save_path,\\\n",
    "            datalist, int(PATCHSIZE), int(STRIDESIZE[t_i]),\n",
    "            level, scale_level, datatypes[t_i], \\\n",
    "            MAXWORKERS)\n",
    "print('cost time:', time.time()-rct)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
